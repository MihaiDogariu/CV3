{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/CV3/blob/main/CV3/colocviu/CV3%20Colocviu%202024-2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se dorește scrierea unei aplicații de image clustering care grupează imaginile similare. În acest sens, trebuie construit un autoencoder care va învăța particularitățile bazei de date de antrenare. După aceea, se vor extrage reprezentările latente (bottleneck) ale bazei de date și se va rula un algoritm simplu de clustering pe ele (k-means). Rezultatul se va compara cu clusterizarea imaginilor în spațiul pixelilor. Succint, pașii ce trebuie urmați sunt:\n",
        "- Antrenarea unui autoencoder pe baza de date de **antrenare**\n",
        "- Extragerea vectorilor latenți ai imaginilor din baza de date de **testare**\n",
        "- Rularea k-means pe reprezentările latente ale imaginilor din baza de date de **testare**\n",
        "- Rularea k-means pe reprezentările originale (spațiul pixelilor) ale imaginilor din baza de date de **testare**\n",
        "\n",
        "### TODO: ###\n",
        "1. (10p) Definirea arhitecturii autoencoderului - acesta va conține minim 4 straturi în codor, respectiv în decodor.\n",
        "2. (10p) Definirea pipeline-ului de pre-procesare a datelor și antrenare a rețelei neuronale. Vectorul latent va avea dimensiune egală cu numărul de clase din baza de date utilizată.\n",
        "3. (10p) Extragerea descriptorilor de trăsături și stocarea lor (într-o structură uzuală: dictionary, tensor, np array, pkl file, pandas etc.) pentru toate imaginile din baza de date de test;\n",
        "4. (10p) Aplicarea k-means pentru reprezentările latente și pentru imaginile originale în spațiul pixelilor.\n",
        "5. (10p) Reprezentarea vizuală în paralel a rezultatelor celor 2 clusterizări. (vezi M4, pag. 33)\n",
        "\n",
        "## Precizări: ##\n",
        "- Se notează aplicarea corectă a conceptelor și scrierea corectă a codului, nu optimizarea rezultatelor.\n",
        "- Arhitectura propriu-zisă a autoencoderului (număr maxim de straturi, tipul lor, funcții de activare, regularizare etc.) este lăsată la liberă alegere.\n",
        "- Alegerea hiperparametrilor, a metodelor de augmentare, pre-procesare și a funcțiilor de cost rămân la latitudinea studenților.\n",
        "- Codul trebuie sa fie funcțional end-to-end. Instalarea eventualelor biblioteci suplimentare trebuie să fie făcută programatic și inclusă în codul încărcat.\n",
        "- Antrenarea se va rula pe un număr redus (3-5) de epoci, preferabil pe CPU. Desi o asemenea problema ar necesita GPU, ne intereseaza doar caracterul funcțional al aplicației.\n",
        "- Fișierul .ipynb se va încărca pe Moodle."
      ],
      "metadata": {
        "id": "pf0xbqhjUAfz",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bzqTZAYnI38T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarcarea bazei de date MNIST Digits\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "FGkEKpm-xekA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forwar(self, x):\n",
        "        pass"
      ],
      "metadata": {
        "id": "l8CxPcyKz-Qh",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Subiectul 3 - impactul impartirii bazei de date\n",
        "Completati codul de mai jos cu secventa necesara astfel incat sa afisati acuratetea modelului pe baza de date de **test**. Impartirea train-val-test se va face conform ponderii 40-30-30, iar antrenarea se va rula timp de 400 de epoci."
      ],
      "metadata": {
        "id": "M0GdQZn0KHtI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpAc50W-5jqS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd # utilitar folosit pentru gestionarea bazelor de date\n",
        "from sklearn.model_selection import train_test_split # va fi utilizat pentru împărțirea bazei de date în subseturile dorite\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_SEED = 1 # pentru reproductibilitate\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "!gdown 1D-Ua952YzK95yPCJxzr8SWu7ZJGVROJd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('weatherAUS.csv')\n",
        "\n",
        "# Baza de date conține o gamă largă de atribute, însă nu ne interesează toate.\n",
        "# Facem o listă cu descriptorii care sunt de interes dintre toți cei disponibili\n",
        "# TODO: testați cu diferiți descriptori pentru a vedea care dintre ei are o influență mai mare asupra capacității de predicție - adăugați cel puțin 2 alți descriptori existenți în baza de date\n",
        "keep = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity3pm', 'Pressure9am', 'RainToday', 'RainTomorrow']\n",
        "\n",
        "# Din întreaga bază de date păstrăm doar datele asociate descriptorilor selectați mai sus\n",
        "df_keep = df[keep]\n",
        "\n",
        "# Unii dintre descriptori sunt reprezentați de valori logice binare (yes/no). Acestea trebuie interpretate sub forma unor valori pe care o rețea neuronală le poate procesa, adică valori numerice.\n",
        "df_keep['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
        "df_keep['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
        "\n",
        "# De asemenea, baza de date conține intrări pentru care nu sunt disponibili toți descriptorii (valori de NaN). O soluție trivială este să eliminăm complet aceste intrări.\n",
        "# TODO: propuneți o altă strategie de abordare a datelor incomplete în acest context.\n",
        "df_keep = df_keep.dropna(how='any')\n",
        "\n",
        "rain = df_keep[df_keep['RainTomorrow']==1] # selectăm doar intrările pentru care a fost înregistrată ploaie\n",
        "no_rain = df_keep[df_keep['RainTomorrow']==0] # selectăm doar intrările pentru care nu a fost înregistrată ploaie\n",
        "no_rain = no_rain.sample(n=len(rain)) # alegem len(rain) eșantioane aleatoare din baza de date no_rain\n",
        "df_keep = pd.concat([rain,no_rain],axis=0) # concatenăm cele 2 subseturi de date, formând o bază de date cu gradul dorit de dezechilibru\n",
        "\n",
        "x = df_keep[keep[:-1]]\n",
        "y = df_keep[keep[-1]]"
      ],
      "metadata": {
        "id": "QmmkMfi9Ry7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=test_ratio)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=val_ratio/(val_ratio + train_ratio))\n",
        "\n",
        "x_train = torch.from_numpy(x_train.to_numpy()).float()\n",
        "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
        "\n",
        "x_val = torch.from_numpy(x_val.to_numpy()).float()\n",
        "y_val = torch.squeeze(torch.from_numpy(y_val.to_numpy()).float())\n",
        "\n",
        "x_test = torch.from_numpy(x_test.to_numpy()).float()\n",
        "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "k65jnrT5l-qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, n_features):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(n_features, 5) \n",
        "    self.fc2 = torch.nn.Linear(5, 3) \n",
        "    self.fc3 = torch.nn.Linear(3, 1) \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.nn.functional.relu(self.fc1(x))\n",
        "    x = torch.nn.functional.relu(self.fc2(x))\n",
        "    return torch.sigmoid(self.fc3(x))"
      ],
      "metadata": {
        "id": "sDpO8Pl8mTqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=Net(x_train.shape[1])\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "\n",
        "x_val = x_val.to(device)\n",
        "y_val = y_val.to(device)\n",
        "\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "net = net.to(device)\n",
        "\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "frhlNoItnPhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funcții auxiliare"
      ],
      "metadata": {
        "id": "pv_gU9U_bKJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcție de calcul a acurateții.\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "  predicted = y_pred.ge(.5).view(-1)\n",
        "  return (y_true == predicted).sum().float() / len(y_true)\n",
        "\n",
        "# Funcție de rotunjire a unui tensor la un anumit număr de zecimale \n",
        "def round_tensor(t, decimal_places=3):\n",
        "  return round(t.item(), decimal_places)"
      ],
      "metadata": {
        "id": "q1iy47cbnZSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antrenarea propriu-zisă"
      ],
      "metadata": {
        "id": "PE9K7L1Sb7jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1000):\n",
        "    \n",
        "    y_pred = net(x_train)\n",
        "    y_pred = torch.squeeze(y_pred)\n",
        "    train_loss = criterion(y_pred, y_train)\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      train_acc = calculate_accuracy(y_train, y_pred)\n",
        "\n",
        "      y_val_pred = net(x_val) \n",
        "      y_pred = torch.squeeze(y_pred)\n",
        "      y_val_pred = torch.squeeze(y_val_pred)\n",
        "\n",
        "      val_loss = criterion(y_val_pred, y_val)\n",
        "\n",
        "      val_acc = calculate_accuracy(y_val, y_val_pred) \n",
        "      print(\"epoch {}\\nTrain set - loss: {}, accuracy: {}\\nTest  set - loss: {}, accuracy: {}\"\n",
        "            .format(epoch, \n",
        "                    round_tensor(train_loss), round_tensor(train_acc), \n",
        "                    round_tensor(val_loss), round_tensor(val_acc)))\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    train_loss.backward()\n",
        "    \n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "_nVIaqzNnvXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
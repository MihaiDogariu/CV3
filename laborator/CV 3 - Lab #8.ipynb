{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MihaiDogariu/CV3/blob/main/laborator/CV%203%20-%20Lab%20%238.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Autoencoder\n",
    "În acest laborator vom studia modul de funcționare al autoencoder-ului și vom implementa un caz particular al acestuia: autoencoder-ului de eliminare a zgomotului (denoising autoencoder). Autoencoder-ul presupune transformarea imaginilor de intrare intr-un cod de dimensiune mai mica (undercomplete autoencoder) sau de dimensiune mai mare (overcomplete autoencoder) decat cea a imaginii de intrare.\n",
    "\n",
    "Structura unui autoencoder este cea din Figura 1.\n",
    "<div>\n",
    "  <center>\n",
    "    <img src=\"https://drive.google.com/uc?export=view&id=13B18HaVSoVULk5uMVA4Hv9cOWyneXNV8\" width=\"300\" class=\"center\">\n",
    "    <p>Figura 1. Structura generală a unui autoencoder.</p>\n",
    "  </center>\n",
    "</div>\n",
    "\n",
    "Autoencoder-ul este format din 2 subansamble:\n",
    "- encoder - transformă imaginea de intrare într-un descriptor latent: $h=f(x)$\n",
    "- decoder - transformă descriptorul latent într-o imagine: $r=g(h)=g(f(x))$. Ideal, $g(x) = f^{-1}(x)$, astfel încât $r=x$.\n",
    "\n",
    "Pentru a evalua reconstrucția autoencoder-ului se folosește eroarea pătratică medie:\n",
    "$MSE = \\frac{1}{N}\\sum_{i=1}^{N}{(x_i-r_i)^2}$\n",
    "\n",
    "Un caz particular al autoencoder-ului este autoencoder-ul de eliminare a zgomotului, cu structura din Figura 2.\n",
    "<div>\n",
    "  <center>\n",
    "    <img src=\"https://drive.google.com/uc?export=view&id=1_Cx7qkHIA2K-x6Zx6p-wjB-ge11KaM5D\" width=\"300\" class=\"center\">\n",
    "    <p>Figura 2. Structura generală a unui autoencoder de eliminare a zgomotului.</p>\n",
    "  </center>\n",
    "</div>\n",
    "\n",
    "În acest caz se adaugă o \"corupere\" a imaginii de intrare, i.e. se adaugă zgomot peste imaginea de intrare și autoencoder-ul este forțat să învețe să reproducă imaginea fără zgomot. În acest caz:\n",
    "- intrarea cu zgomot: $\\tilde{x}=x+n$, unde $n$ este zgomot alb Gaussian\n",
    "- encoder: $h=f(\\tilde{x})$\n",
    "- decoder: $r=g(h)=g(f(\\tilde{x}))=g(f(x+n))\\approx{x}$\n",
    "\n",
    "Pentru a evalua reconstrucția autoencoder-ului se folosește eroarea pătratică medie, la fel ca în cazul autoencoder-ului original.\n",
    "\n",
    "#TODO:\n",
    "1. găsiți o valoare acceptabilă a hiperparametrilor astfel încât reconstrucția imaginilor să fie acceptabilă;\n",
    "2. scrieți funcția de adăugare a zgomotului alb Gaussian;\n",
    "3. înlocuiți encoder-ul și decoder-ul cu niște arhitecturi complet conectate (fully connected layers)."
   ],
   "metadata": {
    "id": "HlDwm0w-U2-j",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZruVH697EGdi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRVRvWieEm8u",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#transformare pentru normalizarea datelor de intrare\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# descarcarea bazei de date de train\n",
    "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# descarcarea bazei de date de test\n",
    "validationset = datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n",
    "val_loader = DataLoader(validationset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7uHOmMJH_L_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hiperparametri\n",
    "latent_dims = 10\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "capacity = 64\n",
    "learning_rate = 1e-2\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRQYTT0KIATo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(in_features=c*2*7*7, out_features=latent_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N0tvs8LIHcR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), capacity*2, 7, 7) # unflatten batch of feature vectors to a batch of multi-channel feature maps\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.tanh(self.conv1(x)) # last layer before output is tanh, since the images are normalized and 0-centered\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FsaEqV_IGjq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon\n",
    "\n",
    "    def get_latent_representation(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def get_reconstruction(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# functie de afisare a unei singure imagini\n",
    "def display(img, img_size=28, title=\"\"):\n",
    "    plt.imshow(img.cpu().detach().numpy().reshape((img_size, img_size)), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "3ttYfaNsHCwv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# functie de afisare a unui set de 10 imagini: original + reconstruit\n",
    "def display10(original, reconstructed):\n",
    "  n = 10\n",
    "  plt.figure(figsize=(30, 6))\n",
    "  for i in range(n):\n",
    "    # afisare original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(original.cpu().detach().numpy()[i].squeeze())\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # afisare reconstructie\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed.cpu().detach().numpy()[i].squeeze())\n",
    "    plt.title(\"reconstruit\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "jgSMcukEKZ6R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# functie de afisare a unui set de 10 imagini: original + zgomots + reconstruit\n",
    "def display10_denoising(original, noisy, reconstructed):\n",
    "  n = 10\n",
    "  plt.figure(figsize=(30, 6))\n",
    "  for i in range(n):\n",
    "    # afisare original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(original.cpu().detach().numpy()[i].squeeze())\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # afisare zgomots\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(noisy.cpu().detach().numpy()[i].squeeze())\n",
    "    plt.title(\"zgomotos\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # afisare reconstructie\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(reconstructed.cpu().detach().numpy()[i].squeeze())\n",
    "    plt.title(\"reconstruit\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "noWE4t7vTwT2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_noise(original_batch, mean=0., std=0.2):\n",
    "#TODO"
   ],
   "metadata": {
    "id": "awJPOwifLoFJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "876Gym0rFE43",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder = autoencoder.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in autoencoder.parameters() if p.requires_grad)\n",
    "print('Number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmHt3WYJImd3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=autoencoder.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# setam in modul de train\n",
    "autoencoder.train()\n",
    "\n",
    "denoising = True\n",
    "\n",
    "train_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for image_batch, _ in train_loader:\n",
    "        if denoising:\n",
    "            noisy_image_batch = add_noise(image_batch)\n",
    "\n",
    "        image_batch = image_batch.to(device)\n",
    "        \n",
    "        if denoising:\n",
    "            image_batch_recon = autoencoder(noisy_image_batch.to(device))\n",
    "        else:\n",
    "            image_batch_recon = autoencoder(image_batch)\n",
    "        \n",
    "        # eroarea de reconstructie\n",
    "        reconstruction_loss = loss(image_batch_recon, image_batch)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction_loss.backward()\n",
    "        \n",
    "        # pas de optimizare\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg[-1] += reconstruction_loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    print('Epoca [%d / %d] Eroare de reconstructie medie: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# setam autoencoderul in modul de test\n",
    "autoencoder.eval()\n",
    "\n",
    "# extragem un batch din setul de testare si il procesam cu autoencoderul\n",
    "val_batch_original = next(iter(val_loader))[0]\n",
    "if denoising:\n",
    "    val_batch_noisy = add_noise(val_batch_original)\n",
    "    val_batch_noisy = val_batch_noisy.to(device)\n",
    "    val_batch_original = val_batch_original.to(device)\n",
    "    val_batch_reconstructed = autoencoder(val_batch_noisy)\n",
    "else:\n",
    "    val_batch_original = val_batch_original.to(device)\n",
    "    val_batch_reconstructed = autoencoder(val_batch_original)"
   ],
   "metadata": {
    "id": "EMgS22L-FFMv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if denoising:\n",
    "    display10_denoising(val_batch_original, val_batch_noisy, val_batch_reconstructed)\n",
    "else:\n",
    "    display10(val_batch_original, val_batch_reconstructed)"
   ],
   "metadata": {
    "id": "g17MM9JsG7Z4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "L_iPOCwrXK92",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNewEuawafKfEomHaACzVkO",
   "include_colab_link": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
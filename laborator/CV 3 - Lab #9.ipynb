{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/CV3/blob/main/laborator/CV%203%20-%20Lab%20%239.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlDwm0w-U2-j"
      },
      "source": [
        "# Variational Autoencoder\n",
        "În acest laborator vom studia modul de funcționare al autoencoder-ului variațional și vom implementa câteva cazuri particulare ale acestuia.\n",
        "\n",
        "Structura unui autoencoder variațional este cea din Figura 1.\n",
        "<div>\n",
        "  <center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=19xaohSDC69CnfsICxrGF5dLaMbZk3aPI\" width=\"400\" class=\"center\">\n",
        "    <p>Figura 1. Structura generală a unui autoencoder variațional.</p>\n",
        "  </center>\n",
        "</div>\n",
        "\n",
        "Autoencoder-ul variațional este un caz particular de autoencoder, specializat în generarea de eșantioane noi. El este format din 2 subansamble, asemenea autoencoder-ului:\n",
        "- encoder - transformă imaginea de intrare într-un descriptor latent: $h=f(x)$\n",
        "- decoder - transformă descriptorul latent într-o imagine: $r=g(h)=g(f(x))$. Ideal, $g(x) = f^{-1}(x)$, astfel încât $r=x$.\n",
        "\n",
        "Spre deosebire de autoencoder, obținerea $h=f(x)$ nu se face direct din parcurgerea rețelei neuronale, ci este necesar un pas suplimentar de eșantionare. Fiecare valoare $h$ se obține ca un eșantion extras din distribuția de probabilitate $\\mathcal{N}(\\mu, \\sigma^2)$, unde $\\mu$ reprezintă media distribuției, iar $\\sigma$ deviația standard, ambele fiind entități ce pot fi învățate de către VAE. Problema apare în momentul în care se extrage un eșantion aleator din această distribuție, deoarece acesta este un proces nedeterminist și nu poate fi învățat (nu poate fi calculat și propagat gradientul pentru o operație aleatoare). Prin urmare, se apelează la o tehnică de reparametrizare, care mută componenta aleatoare în afara rețelei, ca în Figura 2.\n",
        "\n",
        "<div>\n",
        "  <center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1WaM5AN4l21xHikF3HqStoS7RKUjsmuod\" width=\"500\" class=\"center\">\n",
        "    <p>Figura 2. Structura generală a unui autoencoder variațional.</p>\n",
        "  </center>\n",
        "</div>\n",
        "\n",
        "În acest fel, $h$ se obține tot ca un eșantion extras din distribuția de probabilitate $\\mathcal{N}(\\mu, \\sigma^2)$, însă acesta este reparametrizat în $\\mu+\\sigma\\times\\varepsilon$, cu $\\varepsilon\\sim\\mathcal{N}(0, I)$.\n",
        "\n",
        "Antrenarea VAE se face minimizând funcția de cost:\n",
        "\n",
        "$\\mathcal{L}=Loss_{reconstrucție}+Loss_{similaritate}$, unde\n",
        "\n",
        "$Loss_{reconstrucție}=\\mathbb{E}_{q_\\phi}[\\log{p_\\theta(x|z))}]$\n",
        "\n",
        "$Loss_{similaritate}=-D_{KL}(q_\\phi(z)||p(z))$\n",
        "\n",
        "#TODO:\n",
        "1. Rulați antrenarea autoencoderului variațional cu o dimensiune mai mare a spațiului latent. O capacitate mai mare a rețelei duce, teoretic, la exemple generate mai clare.\n",
        "1. Rulați antrenarea autoencoderului variațional cu un număr mai mare de epoci și observați care este punctul în care imaginile încep să devină lizibile.\n",
        "1. Completați codul aferent evaluării modelului.\n",
        "1. Modificați codul astfel încât să obțineți o tranziție mai lentă între eșantioanele interpolate.\n",
        "1. Modificați codul astfel încât să obțineți mai puține imagini în spațiul latent 2D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4JJeD2iaDu6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PBUZh-sRHi-"
      },
      "source": [
        "# Setarea hiperparametrilor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElB5qjG2Zs87"
      },
      "outputs": [],
      "source": [
        "latent_dims = 2\n",
        "# latent_dims = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "capacity = 64\n",
        "learning_rate = 1e-3\n",
        "variational_beta = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN7YCyICRBgv"
      },
      "source": [
        "#Descărcarea și pregătirea bazei de date MNIST Digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBMcxp9uZwh7"
      },
      "outputs": [],
      "source": [
        "# Descarcarea bazei de date MNIST Digits\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_jwOZN2RQSh"
      },
      "source": [
        "# Definirea modelului VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs0lvQNZTtWv"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        c = capacity\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
        "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
        "        self.fc_mu = nn.Linear(in_features=c*2*7*7, out_features=latent_dims) # mu reprezinta vectorul mediilor\n",
        "        self.fc_logvar = nn.Linear(in_features=c*2*7*7, out_features=latent_dims) # logvar reprezinta vectorul \n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        x_mu = self.fc_mu(x)\n",
        "        x_logvar = self.fc_logvar(x)\n",
        "        return x_mu, x_logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        c = capacity\n",
        "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), capacity*2, 7, 7) # unflatten\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.sigmoid(self.conv1(x)) # se foloseste sigmoid datorita functiei de reconstructie BCE\n",
        "        return x\n",
        "    \n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        latent_mu, latent_logvar = self.encoder(x)\n",
        "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
        "        x_reconstruit = self.decoder(latent)\n",
        "        return x_reconstruit, latent_mu, latent_logvar\n",
        "    \n",
        "    def latent_sample(self, mu, logvar):\n",
        "        if self.training:\n",
        "            # reparametrizarea\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.empty_like(std).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "    \n",
        "def vae_loss(x_reconstruit, x, mu, logvar):\n",
        "    loss_reconstructie = F.binary_cross_entropy(x_reconstruit.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "    loss_similaritate = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # divergenta Kullback-Leibler\n",
        "    return loss_reconstructie + variational_beta * loss_similaritate # variational_beta este un parametru care controleaza aportul celor 2 componente la functia de pierdere finala"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J26feOwPb7eF"
      },
      "outputs": [],
      "source": [
        "vae = VariationalAutoencoder()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "vae = vae.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SVPPrsPTw89"
      },
      "source": [
        "# Antrenarea VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "th55VmUtcqb4"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params=vae.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "# set to training mode\n",
        "vae.train()\n",
        "\n",
        "train_loss_avg = []\n",
        "\n",
        "print('Training ...')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss_avg.append(0)\n",
        "    num_batches = 0\n",
        "    \n",
        "    for image_batch, _ in train_dataloader:\n",
        "        \n",
        "        image_batch = image_batch.to(device)\n",
        "\n",
        "        # reconstructia x -> codor -> h -> decodor -> x_reconstruit\n",
        "        image_batch_reconstruit, latent_mu, latent_logvar = vae(image_batch)\n",
        "        \n",
        "        # eroarea variationala (Evidence Lower Bound - ELBO)\n",
        "        loss = vae_loss(image_batch_reconstruit, image_batch, latent_mu, latent_logvar)\n",
        "        \n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # actualizarea ponderilor retelei\n",
        "        optimizer.step()\n",
        "        \n",
        "        # acumularea erorii la fiecare iteratie\n",
        "        train_loss_avg[-1] += loss.item()\n",
        "        num_batches += 1\n",
        "        \n",
        "    # medierea erorii pe intreaga epoca\n",
        "    train_loss_avg[-1] /= num_batches\n",
        "    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bbPm8OUUlwS"
      },
      "source": [
        "# Afișarea curbei erorii de antrenare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g7PW9joIcGLl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(train_loss_avg)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyHksE7dU5D_"
      },
      "source": [
        "# Evaluarea pe baza de date de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BmUpCrrliyLN"
      },
      "outputs": [],
      "source": [
        "# Setarea autoencoderului variational in modul de evaluare\n",
        "vae.eval()\n",
        "\n",
        "test_loss_avg, num_batches = 0, 0\n",
        "\n",
        "#TODO\n",
        "    \n",
        "test_loss_avg /= num_batches\n",
        "print('average reconstruction error: %f' % (test_loss_avg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYaMrX65VCOY"
      },
      "source": [
        "# Vizualizarea reconstrucției"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3xw_nXx3jrhw"
      },
      "outputs": [],
      "source": [
        "# Vizualizarea reconstructiei\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "import torchvision.utils\n",
        "\n",
        "vae.eval()\n",
        "\n",
        "def to_img(x):\n",
        "    x = x.clamp(0, 1) # unele valori pot depasi intervalul [0, 1]\n",
        "    return x\n",
        "\n",
        "def show_image(img):\n",
        "    img = to_img(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def visualise_output(images, model):\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        images = images.to(device)\n",
        "        images, _, _ = model(images)\n",
        "        images = images.cpu()\n",
        "        # images = to_img(images)\n",
        "        np_imagegrid = torchvision.utils.make_grid(images[1:50], 10, 5).numpy()\n",
        "        plt.imshow(np.transpose(np_imagegrid, (1, 2, 0)))\n",
        "        plt.show()\n",
        "\n",
        "images, labels = next(iter(test_dataloader))\n",
        "\n",
        "# Afisarae imaginilor originale\n",
        "print('Imagini originale')\n",
        "show_image(torchvision.utils.make_grid(images[1:50],10,5))\n",
        "plt.show()\n",
        "\n",
        "# Afisarea imaginilor reconstruite de catre VAE\n",
        "print('Imagini reconstruite de catre VAE')\n",
        "visualise_output(images, vae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGx_7Yg0YRjg"
      },
      "source": [
        "# Utilizarea VAE pentru generare de eșantioane noi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b9h1NYA_kSHn"
      },
      "outputs": [],
      "source": [
        "vae.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # esantionare vectorilor latenti din distributia latenta\n",
        "    latent = torch.randn(128, latent_dims, device=device)\n",
        "\n",
        "    # reconstruirea imaginilor din vectorii latenti\n",
        "    img_recon = vae.decoder(latent)\n",
        "    img_recon = img_recon.cpu()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    show_image(torchvision.utils.make_grid(img_recon.data[:100],10,5))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYcbIUr2Xe54"
      },
      "source": [
        "# Interpolare in spațiul latent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vOuJ-QGgXMaJ"
      },
      "outputs": [],
      "source": [
        "vae.eval()\n",
        "\n",
        "def interpolation(lambda1, model, img1, img2):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        # vectorul latent al primei imagini\n",
        "        img1 = img1.to(device)\n",
        "        latent_1, _ = model.encoder(img1)\n",
        "\n",
        "        # vectorul latent al celei de-a doua imagini\n",
        "        img2 = img2.to(device)\n",
        "        latent_2, _ = model.encoder(img2)\n",
        "\n",
        "        # interpolarea intre cei doi vectori cu factorul lambda - lambda controleaza numarul pasului de interpolare\n",
        "        inter_latent = lambda1* latent_1 + (1- lambda1) * latent_2\n",
        "\n",
        "        # reconstructia imaginii interpolate\n",
        "        inter_image = model.decoder(inter_latent)\n",
        "        inter_image = inter_image.cpu()\n",
        "\n",
        "        return inter_image\n",
        "    \n",
        "# sortarea imaginilor in functie de cifra pe care o reprezinta\n",
        "digits = [[] for _ in range(10)]\n",
        "for img_batch, label_batch in test_dataloader:\n",
        "    for i in range(img_batch.size(0)):\n",
        "        digits[label_batch[i]].append(img_batch[i:i+1])\n",
        "    if sum(len(d) for d in digits) >= 1000:\n",
        "        break;\n",
        "\n",
        "# calcularea parametrilor lambda - cel de-al treilea argument ne arata numarul de pasi de interpolare pe care ii vom realiza; un numar mai mare duce la tranzitii mai lente intre imagini\n",
        "lambda_range=np.linspace(0,1,10)\n",
        "\n",
        "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "\n",
        "for ind,l in enumerate(lambda_range):\n",
        "    inter_image=interpolation(float(l), vae, digits[7][0], digits[1][0])\n",
        "   \n",
        "    inter_image = to_img(inter_image)\n",
        "    \n",
        "    image = inter_image.numpy()\n",
        "   \n",
        "    axs[ind].imshow(image[0,0,:,:], cmap='gray')\n",
        "    axs[ind].set_title('lambda_val='+str(round(l,1)))\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg8sBLOhYszM"
      },
      "source": [
        "# Afișarea spațiului latent 2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v7MxHdZukTaU"
      },
      "outputs": [],
      "source": [
        "# Acest subpunct are sens doar in cazul in care dimensiunea vectorului latent este 2\n",
        "if latent_dims != 2:\n",
        "    print('Please change the parameters to two latent dimensions.')\n",
        "    \n",
        "with torch.no_grad():\n",
        "    \n",
        "    # crearea unui spatiu latent 2D\n",
        "    latent_x = np.linspace(-1.5,1.5,20)\n",
        "    latent_y = np.linspace(-1.5,1.5,20)\n",
        "    latents = torch.FloatTensor(len(latent_y), len(latent_x), 2)\n",
        "    for i, lx in enumerate(latent_x):\n",
        "        for j, ly in enumerate(latent_y):\n",
        "            latents[j, i, 0] = lx\n",
        "            latents[j, i, 1] = ly\n",
        "    latents = latents.view(-1, 2) # flatten in batch\n",
        "\n",
        "    # reconstructia imaginilor din vectorii latenti\n",
        "    latents = latents.to(device)\n",
        "    image_recon = vae.decoder(latents)\n",
        "    image_recon = image_recon.cpu()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    show_image(torchvision.utils.make_grid(image_recon.data[:400],20,5))\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLvhXH03RAI9QO4AMq2Gx3",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
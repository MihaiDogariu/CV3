{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvwaUpNvyPIQu8HVkZKSSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/CV3/blob/main/laborator/CV%203%20-%20Lab%20%235.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image Retrieval\n",
        "Acest proiect implementeaza o retea neuronala pentru clasificarea imaginilor reale si foloseste descriptorii extrasi cu ajutorul ei pentru a efectua image retrieval. Baza de date aleasa pentru demonstratie este CIFAR10."
      ],
      "metadata": {
        "id": "cVj8IalH4YlD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nROe8lDRLzn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Alegem configuratia sistemului (cpu/gpu)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Setam media si deviatia standard pentru normalizarea bazei de date - acestea sunt calculate la nivel de canal si doar pe baza de date de antrenare!\n",
        "mean=[0.4914, 0.4822, 0.4465]\n",
        "std=[0.2023, 0.1994, 0.2010]\n",
        "normalize = transforms.Normalize(mean, std)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Pre-procesarea datelor"
      ],
      "metadata": {
        "id": "Dj5xxj71llow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_valid_loader(data_dir,\n",
        "                           batch_size,\n",
        "                           augment,\n",
        "                           random_seed,\n",
        "                           normalize,\n",
        "                           valid_size=0.1,\n",
        "                           shuffle=True):\n",
        "\n",
        "    # Definim setul de transformari necesare bazei de date\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)), # baza de date CIFAR10 contine imagini de dimensiunea 32x32, iar AlexNet are intrari de dimensiune 227x227\n",
        "            transforms.ToTensor(),        # transformarea intrarilor in tensori\n",
        "            normalize,                    # aplicarea normalizarii\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            # transforms.RandomCrop(32, padding=4), # decuparea unor regiuni aleatoare de dimensiune 32x32 din imaginea originala la care s-a adaugat padding=4\n",
        "            transforms.RandomHorizontalFlip(0.4), # oglindirea imaginilor cu probabilitate de 40%\n",
        "            transforms.Resize((227,227)),         # redimensionarea imaginilor augmentate la dimensiunea de 227x227 pixeli\n",
        "            transforms.ToTensor(),                # transformarea intrarilor in tensori\n",
        "            normalize,                            # aplicarea normalizarii\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = valid_transform\n",
        "\n",
        "    # Fiind o baza de date foarte populara, CIFAR10 poate fi descarcata cu ajutorul modulului torchvision\n",
        "    train_dataset = datasets.CIFAR10(root=data_dir,\n",
        "                                     train=True,\n",
        "                                     download=True,\n",
        "                                     transform=train_transform,\n",
        "                                     )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(root=data_dir,\n",
        "                                     train=True,\n",
        "                                     download=True,\n",
        "                                     transform=valid_transform,\n",
        "                                     )\n",
        "\n",
        "    # Alegem numarul de esantioane pentru train/val\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    # Amestecam indecsii\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    # Separam indecsii de train in train+val\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # Cream dataloaders pentru train si val\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "def get_test_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    normalize,\n",
        "                    shuffle=True):\n",
        "\n",
        "    # Transformari asemanatoare cu cele pentru train/val. Normalizarea se face cu aceleasi valori ca in cazul train!\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((227,227)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    # Descarcarea bazei de test\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=False,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    # Crearea dataloader pentru test\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# Crearea efectiva a dataloaders\n",
        "train_loader, valid_loader = get_train_valid_loader(\n",
        "    data_dir = './data',\n",
        "    batch_size = 64,\n",
        "    augment = True,\n",
        "    random_seed = 1,\n",
        "    normalize = normalize\n",
        ")\n",
        "\n",
        "test_loader = get_test_loader(\n",
        "    data_dir = './data',\n",
        "    batch_size = 64,\n",
        "    normalize = normalize\n",
        ")"
      ],
      "metadata": {
        "id": "N4sJfy7RVUGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pentru a vizualiza corect imaginile care au fost deja normalizate, trebuie sa le \"denormalizam\". Clasa de mai jos implementeaza operatia inversa normalizarii. Apeland-o pentru o imagine normalizata, se va obtine imaginea originala, care poate fi afisata corect."
      ],
      "metadata": {
        "id": "tHBgW9cNKUhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor\n",
        "\n",
        "unorm = UnNormalize(mean, std)"
      ],
      "metadata": {
        "id": "45PjAUvAC3Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplu de acces al unei imagini din baza de date folosind obiectul de tip DataLoader."
      ],
      "metadata": {
        "id": "eyi2oy0MLRUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_loader)) # se extrage un batch de imagini si etichete din baza de date cu ajutorul unui dataloader\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()     # se extrage prima imagine din batch si sunt eliminate dimensiunile de valoare 1\n",
        "img = unorm(img)                      # se \"denormalizeaza\" imaginea\n",
        "npimg = img.numpy()                   # se transforma tensorul in nparray\n",
        "img = np.transpose(npimg, (1, 2, 0))  # imaginile din CIFAR-10 au dimensiunea 3x32x32 (scalata la 3x227x227) - pentru a fi vizualizate corect, acestea trebuie transpuse in 227x227x3\n",
        "label = train_labels[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "lR6ikIAb6N0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Definirea modelului"
      ],
      "metadata": {
        "id": "G90-dEwJ45Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puteti folosi si alt model de retea decat AlexNet. Modele mai putin adanci ar putea fi utilizate cu succes, data fiind dimensiunea redusa a imaginilor."
      ],
      "metadata": {
        "id": "t-s_LREX7Qgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "IzVHcoKlXTko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Antrenarea retelei"
      ],
      "metadata": {
        "id": "G8FsviED5BHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alegerea hiperparametrilor\n",
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Trecerea modelului pe gpu\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "# Alegerea functiei de pierdere. Clasificare de imagini => cross-entropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Alegerea optimizatorului\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)"
      ],
      "metadata": {
        "id": "nxoT-gGLXWKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antrenarea modelului\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Incarcam tensorii pe gpu/cpu\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward propagation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backprop si rularea unui pas de optimizare a ponderilor\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Rularea algoritmului pe baza de validare\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n"
      ],
      "metadata": {
        "id": "wyvxaODWXY_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Testarea retelei"
      ],
      "metadata": {
        "id": "JjNYKyda5E_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rularea algoritmului pe baza de test\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ],
      "metadata": {
        "id": "y9YOC0T0XbyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fluxul de procesari pentru aceasta lucrare se compune din urmatorii pasi:\n",
        "1. antrenarea unui model de clasificare a imaginilor pe baza de date CIFAR-10. Rularea pasilor:\n",
        "  - antrenare pe `train`, testare pe `val`;\n",
        "  - optimizare hiperparametri;\n",
        "  - antrenare pe `train+val`, testare pe `test` - retinere metrici.\n",
        "2. alegerea unei imagini aleatoare din baza de date (query image);\n",
        "3. extragerea descriptorului de trasaturi al imaginii alese;\n",
        "4. parcurgerea intregii baze de date (`train` + `val` + `test`) si extragerea descriptorului de trasaturi al fiecarei imagini, in parte;\n",
        "5. compararea descriptorului query cu descriptorul fiecarei imagini si retinerea distantei dintre cei 2 descriptori (se poate folosi distanta euclidiana sau distanta cosinus);\n",
        "6. ordonarea distantelor dintre query si imagini;\n",
        "7. determinarea celei mai asemanatoare imagini pe baza distantei minime;\n",
        "8. alegerea top-k a rezultatelor;\n",
        "9. calcularea metricilor `precision` si `recall`.\n",
        "\n",
        "#\\#TODO:\n",
        "1. implementati fluxul descris mai sus;\n",
        "2. incercati sa extrageti descriptorii de trasaturi din diferite straturi ale retelei neuronale;\n",
        "3. rulati antrenarea modelului cu 1, 2, 5, 10, 20 epoci si urmariti cum anume se modifica metricile;\n",
        "4. incercati concatenarea descriptorilor de pe diferite straturi si urmariti efectul asupra metricilor - teoretic, fiecare strat aduce o contributie in plus la reprezentarea finala si descrierea imaginii ar trebui sa fie mai completa."
      ],
      "metadata": {
        "id": "uykiqMdy3Ceh"
      }
    }
  ]
}
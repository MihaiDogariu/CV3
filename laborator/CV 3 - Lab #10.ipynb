{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhsPWj9G+exq0iEcCtTz4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/CV3/blob/main/laborator/CV%203%20-%20Lab%20%2310.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network\n",
        "Rețelele generative adversariale au scopul de genera eșantioane noi, nemaiîntâlnite în baza de date de antrenare. Pentru a realiza acest lucru, 2 rețele diferite (generator-G și discriminator-D) sunt puse în competiție, una împotriva celeilalte:\n",
        "- Discriminatorul are rolul de a determina dacă un eșantion pe care îl \"vede\" provine din baza de date cu exemple reale sau dacă a fost sintetizat de către generator. \n",
        "- Generatorul are rolul de a crea eșantioane care să păcălească discriminatorul, acesta clasificându-le ca fiind reale.\n",
        "\n",
        "<div>\n",
        "  <center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1_nqS1h64r_txvmL13TRNeepz3eKODEYx\" width=\"400\" class=\"center\">\n",
        "    <p>Figura 1. Structura generală a unui GAN.</p>\n",
        "  </center>\n",
        "</div>\n",
        "\n",
        "În acest sens, întregul ansamblu este antrenat pentru a optimiza funcția mini-max:\n",
        "\n",
        "$\\displaystyle\\min_{\\theta}\\max_{\\phi}V(G_{\\theta},D_{\\phi})=\\mathbb{E}_{x\\sim p_{data}}[\\log D_{\\phi}(x)] + \\mathbb{E}_{z\\sim p_{z}}[\\log (1 - D_{\\phi}(G_{\\theta}(z)))]$\n",
        "\n",
        "Laboratorul curent se axează pe antrenarea unui GAN pentru a genera fețe de persoane pornind de la baza de date CelebA.\n",
        "\n",
        "TODO:\n",
        "1. Generati doi vectori latenti diferiti si interpolarea dintre ei in 20 de pasi. Rulati generatorul pe toti acesti vectori si observati trecerea de la o imagine la cealalta, ca urmare a interpolarii in spatiul latent.\n",
        "1. Generati un vector latent. Modificati, pe rand, doar cate o componenta a acestui vector latent si observati diferenta care apare in spatiul imaginilor intre imaginea generata cu vectorul latent original si vectorul latent alterat.\n",
        "1. Generati 100 vectori latenti si afisati-i intr-o matrice 10 x 10. Selectati 3 grupuri a cate 3 vectori care va genereaza imagini cu caracteristici similare (e.g. 3 vectori care genereaza femei cu par blond, 3 vectori care genereaza barbati cu barba etc.). Gasiti media fiecarui set de cate 3 vectori si realizati operatii aritmetice intre mediile respective asemanator slide-ului 76 din modulul M4."
      ],
      "metadata": {
        "id": "2VIf7IkQajj6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CosXdRIIFhn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import gdown\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manual_seed = 999\n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)"
      ],
      "metadata": {
        "id": "K_aKRSEPILPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarcarea bazei de date"
      ],
      "metadata": {
        "id": "yipab2FkaFxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
        "\n",
        "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"data_faces/\")\n",
        "\n",
        "data_root = 'data_faces'\n",
        "img_folder = 'data_faces/img_align_celeba'\n",
        "img_list = os.listdir(img_folder)\n",
        "print(\"Total imagini: {}\".format(len(img_list)))"
      ],
      "metadata": {
        "id": "y2EXU8u3IRyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasa pentru a prelucra baza de date CelebA"
      ],
      "metadata": {
        "id": "ujVFsTGsaB7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, root_dir, transform=None):\n",
        "    # Citire imagini din root_dir\n",
        "    image_names = os.listdir(root_dir)\n",
        "\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform \n",
        "    self.image_names = natsorted(image_names)\n",
        "\n",
        "  def __len__(self): \n",
        "    return len(self.image_names)\n",
        "\n",
        "  def __getitem__(self, idx): # functie necesara pentru dataloader\n",
        "    img_path = os.path.join(self.root_dir, self.image_names[idx])\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "muUmJqLIMsIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregatirea bazei de date"
      ],
      "metadata": {
        "id": "O1eLheJKZ_Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiunea la care vor fi redimensionate imaginile\n",
        "image_size = 64\n",
        "# Transformarile aplicate pe baza de date\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Incarcarea bazei de date si aplicarea transformarilor\n",
        "celeba_dataset = CelebADataset(f'{img_folder}', transform)"
      ],
      "metadata": {
        "id": "WgL_Lm_NMvV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setarea dataloader-ului"
      ],
      "metadata": {
        "id": "y_UMTc1kZ8tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setarea parametrilor pentru dataloader\n",
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 0 if device.type == 'cuda' else 2\n",
        "pin_memory = True if device.type == 'cuda' else False\n",
        "\n",
        "celeba_dataloader = torch.utils.data.DataLoader(celeba_dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=num_workers,\n",
        "                                                pin_memory=pin_memory,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "id": "H6QkCbTYMxfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspectia vizuala a bazei de date"
      ],
      "metadata": {
        "id": "0PAxQVUSZ3Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu de imagini din baza de date de antrenare\n",
        "real_batch = next(iter(celeba_dataloader))\n",
        "image_grid = vutils.make_grid(real_batch.to(device)[:64],\n",
        "                              padding=2,\n",
        "                              normalize=True).cpu()\n",
        "image_grid = np.transpose(image_grid, (1, 2, 0))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis('off')\n",
        "plt.title('Training Images')\n",
        "plt.imshow(image_grid)"
      ],
      "metadata": {
        "id": "PVytXrJMM22y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functie pentru a initializa ponderile retelelor"
      ],
      "metadata": {
        "id": "mesd_fstZyDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif type(m) == nn.BatchNorm2d:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "W5Ae0Nc4Tdzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crearea blocurilor componente arhitecturii DCGAN\n",
        "Acestea se bazeaza pe straturi uzuale, insa pot fi modularizate in acest fel pentru a reduce codul aferent modelelor propriu-zise"
      ],
      "metadata": {
        "id": "2RYIdSqYZjGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Blocuri utilizate in reteaua DCGAN\n",
        "class ConvTransposeBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride,\n",
        "                 padding,\n",
        "                 bias=False,\n",
        "                 inplace=True):\n",
        "        super(ConvTransposeBlock, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels,\n",
        "                               out_channels,\n",
        "                               kernel_size,\n",
        "                               stride,\n",
        "                               padding,\n",
        "                               bias=bias), nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=inplace))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride,\n",
        "                 padding,\n",
        "                 bias=False,\n",
        "                 inplace=True,\n",
        "                 use_batch_norm=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(\n",
        "            nn.Conv2d(in_channels,\n",
        "                      out_channels,\n",
        "                      kernel_size,\n",
        "                      stride,\n",
        "                      padding,\n",
        "                      bias=bias))\n",
        "        if use_batch_norm:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=inplace))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "KcFOfpMIO2zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crearea modelului generatorului"
      ],
      "metadata": {
        "id": "92CHNQJTZg15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim, base_channels, out_channels):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # Intrarea este vectorul de zgomot, z\n",
        "            ConvTransposeBlock(latent_dim, base_channels * 8, 4, 1,\n",
        "                               0),  # base_channels*8 x 4 x 4\n",
        "            ConvTransposeBlock(base_channels * 8, base_channels * 4, 4, 2,\n",
        "                               1),  # base_channels*4 x 8 x 8\n",
        "            ConvTransposeBlock(base_channels * 4, base_channels * 2, 4, 2,\n",
        "                               1),  # base_channels*2 x 16 x 16\n",
        "            ConvTransposeBlock(base_channels * 2, base_channels, 4, 2,\n",
        "                               1),  # base_channels x 32 x 32\n",
        "            nn.ConvTranspose2d(base_channels, out_channels, 4, 2, 1,\n",
        "                               bias=False),  # out_channels x 64 x 64\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "5RslPUH6Tfsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crearea modelului discriminatorului"
      ],
      "metadata": {
        "id": "_cDPLAiPZeLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, base_channels, in_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # Dimensiunea intrarii este in_channels x 64 x 64\n",
        "            ConvBlock(in_channels, base_channels, 4, 2,\n",
        "                      1),  # base_channels x 32 x 32\n",
        "            ConvBlock(base_channels, base_channels * 2, 4, 2,\n",
        "                      1),  # base_channels*2 x 16 x 16\n",
        "            ConvBlock(base_channels * 2, base_channels * 4, 4, 2,\n",
        "                      1),  # base_channels*4 x 8 x 8\n",
        "            ConvBlock(base_channels * 4, base_channels * 8, 4, 2,\n",
        "                      1),  # base_channels*8 x 4 x 4\n",
        "            nn.Conv2d(base_channels * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "Jv0iwZSuTiJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregatirea generatorului"
      ],
      "metadata": {
        "id": "qpSdaUhUZcci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiunea vectorului de zgomot\n",
        "latent_dim = 100\n",
        "# Numarul de canale ale vectorului de trasaturi al generatorului\n",
        "generator_channels = 64\n",
        "# Numarul de canale ale imaginilor de antrenare\n",
        "image_channels = 3\n",
        "\n",
        "# Crearea generatorului\n",
        "generator = Generator(latent_dim, generator_channels, image_channels).to(device)\n",
        "if (device.type == 'cuda' and ngpu > 0):\n",
        "    generator = nn.DataParallel(generator, list(range(ngpu)))\n",
        "generator.apply(weights_init)\n",
        "\n",
        "generator"
      ],
      "metadata": {
        "id": "IwA3B2D7TpIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregatirea discriminatorului"
      ],
      "metadata": {
        "id": "tGT1WohJZY1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numarul de canale ale vectorului de trasaturi al discriminatorului\n",
        "discriminator_channels = 64\n",
        "\n",
        "# Crearea discriminatorului\n",
        "discriminator = Discriminator(discriminator_channels, image_channels)\n",
        "if (device.type == 'cuda' and ngpu > 0):\n",
        "    discriminator = nn.DataParallel(discriminator, list(range(ngpu)))\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "discriminator"
      ],
      "metadata": {
        "id": "lt4Zkuu1Tq_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setarea hiperparametrilor, a pierderii si a optimizatorului"
      ],
      "metadata": {
        "id": "KaS8CkzwZV05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparametri\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "num_epochs = 10\n",
        "\n",
        "# Functia de pierdere de cross-entropie binara, utilizata pentru a evalua discriminatorul\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizatorul pentru generator\n",
        "generator_optim = torch.optim.Adam(generator.parameters(),\n",
        "                                   lr=lr,\n",
        "                                   betas=(beta1, beta2))\n",
        "# Optimizatorul pentru discriminator\n",
        "discriminator_optim = torch.optim.Adam(discriminator.parameters(),\n",
        "                                       lr=lr,\n",
        "                                       betas=(beta1, beta2))"
      ],
      "metadata": {
        "id": "yJuR91MUTs5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pregatirea componentelor ce vor urmari evolutia antrenarii"
      ],
      "metadata": {
        "id": "eYn8cDmOZQ02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se va folosi un batch de vectori de zgomot pentru a urmari evolutia antrenarii\n",
        "fixed_latent_vectors = torch.randn((64, latent_dim, 1, 1), device=device)\n",
        "\n",
        "# O lista cu imaginile generate de-a lungul antrenarii\n",
        "img_list = []\n",
        "\n",
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "# Retinem numarul de iteratii/batch-uri procesate la fiecare epoca\n",
        "iters = 0"
      ],
      "metadata": {
        "id": "C3653dVFTucf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Antrenarea propriu-zisa"
      ],
      "metadata": {
        "id": "2jaANXKHZK5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Starting training loop...')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, real_batch in enumerate(celeba_dataloader):\n",
        "        # ----------------- Antrenarea Discriminatorului ----------------------\n",
        "        # Scopul antrenarii discriminatorului este de a maximiza log(D(x)) + log(1 - D(G(z)))\n",
        "        \n",
        "        # --- Pasul 1. Procesam un batch de date reale ---\n",
        "        # Resetam gradientul acumulat la pasul anterior\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        # Extragem dimensiunea batch-ului, deoarece ultimul batch poate avea o \n",
        "        # dimensiune diferita fata de cea stabilita ca hiperparametru, in cazul \n",
        "        # in care baza de date nu are un nr de exemple multiplu intreg de batch_size\n",
        "        batch_size = real_batch.size(0)\n",
        "\n",
        "        # Se pot folosi etichete soft, in loc de clasicele 0/1 pentru a avea un\n",
        "        # comportament mai lin al functiei de pierdere.\n",
        "        # In loc de 1, folosim valori aleatoare intre 0.7 si 1.2\n",
        "        real_labels = (1.2 - 0.7) * torch.rand((batch_size,)) + 0.7\n",
        "        real_labels = real_labels.to(device)\n",
        "        real_batch = real_batch.to(device)\n",
        "\n",
        "        # Prelucram batch-ul de date reale cu discriminatorul\n",
        "        output = discriminator(real_batch).view(-1)\n",
        "\n",
        "        # Calculam functia de pierdere si gradientul\n",
        "        discriminator_real_loss = criterion(output, real_labels)\n",
        "        discriminator_real_loss.backward()\n",
        "        \n",
        "        # Retinem iesirea pentru a o afisa pe ecran\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        \n",
        "        # --- Pasul 2. Procesam un batch de date sintetice ---\n",
        "        # Procesarea batch-ului de date sintetice se face mai intai prin generator\n",
        "        # si apoi prin discriminator, D(G(z))\n",
        "        \n",
        "        # Generam un vector de zgomot z\n",
        "        latent_vectors_batch = torch.randn((batch_size, latent_dim, 1, 1),\n",
        "                                           device=device)\n",
        "        # Generam imagini false cu generatorul\n",
        "        fake_batch = generator(latent_vectors_batch)\n",
        "\n",
        "        # Folosim etichete soft, ca in cazul datelor reale\n",
        "        # In loc de 0, folosim valori aleatoare intre 0.0 si 0.3\n",
        "        fake_labels = (0.3 - 0.0) * torch.rand((batch_size,)) + 0.0\n",
        "        fake_labels = fake_labels.to(device)\n",
        "\n",
        "        # Prelucram batch-ul de date sintetice cu discriminatorul\n",
        "        output = discriminator(fake_batch.detach()).view(-1)\n",
        "\n",
        "        # Calculam functia de pierdere si gradientul\n",
        "        discriminator_fake_loss = criterion(output, fake_labels)\n",
        "        discriminator_fake_loss.backward()\n",
        "\n",
        "        # Retinem iesirea pentru a o afisa pe ecran: D(G(z1))\n",
        "        D_G_z1 = discriminator_fake_loss.mean().item()\n",
        "        \n",
        "        # Calculam pierderea totala a discriminatorului\n",
        "        discriminator_loss = discriminator_real_loss + discriminator_fake_loss\n",
        "\n",
        "        # Actualizam ponderile discriminatorului\n",
        "        discriminator_optim.step()\n",
        "        # ---------------- Sfarsit Antrenare Discriminator ---------------------\n",
        "\n",
        "\n",
        "\n",
        "        # ------------------- Antrenarea Generatorului -------------------------\n",
        "        # Scopul antrenarii discriminatorului este de a maximiza log(D(G(z)))\n",
        "        \n",
        "        # Resetam gradientul acumulat la pasul anterior\n",
        "        generator.zero_grad()\n",
        "        \n",
        "        # Procesam prin discriminator batch-ul de date sintetice generat \n",
        "        # la pasul anterior (la antrenarea discriminatorului)\n",
        "        output = discriminator(fake_batch).view(-1)\n",
        "\n",
        "        # Calculam functia de pierdere a generatorului\n",
        "        # In acest caz, generatorul vede toate iesirile sale ca fiind reale, \n",
        "        # deci vom interschimba etichetele sintetice cu cele reale pentru a \n",
        "        # calcula aceasta functie de pierdere\n",
        "        generator_loss = criterion(output, real_labels)\n",
        "\n",
        "        # Calculam gradientul\n",
        "        generator_loss.backward()\n",
        "\n",
        "        # Actualizam ponderile generatorului\n",
        "        generator_optim.step()\n",
        "\n",
        "        # Retinem iesirea pentru a o afisa pe ecran: D(G(z1))\n",
        "         D_G_z2 = output.mean().item()\n",
        "\n",
        "        # Afisam caracteristicile antrenarii la fiecare 50 iteratii\n",
        "        if i % 50 == 0:\n",
        "            print(\n",
        "                f'[{epoch}/{num_epochs - 1}][{i}/{len(celeba_dataloader)}]\\t Loss_D:{discriminator_loss.item():4f} Loss_G:{generator_loss.item():4f} D(x):{D_x:4f} D(G(z)):{D_G_z1:4f}/{D_G_z2:4f}'\n",
        "            )\n",
        "\n",
        "        # Retinem pierderile pentru a le afisa pe grafic\n",
        "        discriminator_losses.append(discriminator_loss.item())\n",
        "        generator_losses.append(generator_loss.item())\n",
        "\n",
        "        # La fiecare 500 de iteratii vom procesa din nou vectorul de zgomot fix,\n",
        "        # generat inainte de antrenare. In felul acesta, vom urmari evolutia \n",
        "        # generatorului pe acelasi vector de zgomot.\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and\n",
        "                                  (i == len(celeba_dataloader) - 1)):\n",
        "            with torch.no_grad():\n",
        "                fixed_generations = generator(\n",
        "                    fixed_latent_vectors).detach().cpu()\n",
        "            img_list.append(\n",
        "                vutils.make_grid(fixed_generations, padding=2, normalize=True))\n",
        "\n",
        "        # Incrementam iteratiile\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "MYSDmVOWTwJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluare cantitativa"
      ],
      "metadata": {
        "id": "aCbFiTEcY4Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afisam pierderile generatorului si ale discriminatorului pe grafic\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(generator_losses, label=\"G\")\n",
        "plt.plot(discriminator_losses, label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GNZ5GyDdTxbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluare calitativa"
      ],
      "metadata": {
        "id": "kzR_qzPqZJKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list\n",
        "      ]\n",
        "ani = animation.ArtistAnimation(fig,\n",
        "                                ims,\n",
        "                                interval=1000,\n",
        "                                repeat_delay=1000,\n",
        "                                blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "metadata": {
        "id": "Bp0vHcdlT1Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dupa antrenarea completa a generatorului si a discriminatorului afisam in\n",
        "# paralel datele reale si cele sintetice pentru a urmari diferentele calitative\n",
        "# Extragem un batch de date reale\n",
        "real_batch = next(iter(celeba_dataloader))\n",
        "\n",
        "# Afisam un batch de date reale\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch.to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Afisam un batch de date sintetizate la ultima epoca\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kib65de0T1T4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ew31qoz2SiNL"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKPYLjwtWcQ26bIcMMFvIQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/CV3/blob/main/laborator/CV%203%20-%20Lab%20%232.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementarea perceptronului\n",
        "Să se implementeze o variantă simplă a perceptronului, care modelează funcțiile logice uzuale."
      ],
      "metadata": {
        "id": "QGxp4xMkJq5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S84icn-I3bfZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array([(0,0), (0,1), (1,0), (1,1)])\n",
        "# TODO: Testati diferite functii logice pentru a vedea care dintre ele poate fi implementata cu un singur perceptron: OR, AND, XOR.\n",
        "# Diferenta intre ele consta in schimbarea etichetelor conform tabelei logice.\n",
        "labels = np.array([0, 1, 1, 1]) # OR\n",
        "\n",
        "# TODO: Testati moduri diferite de a initializa ponderile: 0 vs aleator\n",
        "w = np.array([0, 0, 0])"
      ],
      "metadata": {
        "id": "7k7Cb41T53j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def form_x(x):\n",
        "  return np.concatenate(([1], x))"
      ],
      "metadata": {
        "id": "TaXkdFjL-MT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heaviside(x):\n",
        "  # TODO: implementati functia prag Heaviside"
      ],
      "metadata": {
        "id": "DMnvRnF868r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x, w):\n",
        "  # TODO: implementati activarea perceptronului"
      ],
      "metadata": {
        "id": "Fot5K4lz7JzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "# TODO: Testati algoritmul cu diferite valori pentru lr: 0.01, 0.1, 0.5, 1:\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  print(\"Epoca #{}\".format(epoch))\n",
        "  # Retinem valoarea ponderilor de la inceputul epocii\n",
        "  w_epoch_start = w\n",
        "  w_changed = False\n",
        "  for i, (input_pair, label) in enumerate(zip(input, labels)):\n",
        "    # Adaugam x0=1 la vectorul de intrare\n",
        "    in_values = form_x(input_pair)\n",
        "    # Calculam activarea perceptronului\n",
        "    out_value = forward(in_values, w)\n",
        "    # Actualizam valorile ponderilor\n",
        "    # TODO\n",
        "    # Retinem daca a avut loc modificare ponderilor <-> daca algoritmul inca mai invata\n",
        "    if not (np.array_equal(w, w_epoch_start)):\n",
        "      w_changed = True\n",
        "    # Afisam pe ecran valorile conform tabelului din curs, modulul M2, slide 43\n",
        "    print(in_values, label, out_value, label-out_value, w)\n",
        "  # Daca valorile w nu se schimba pe parcursul unei epoci atunci putem incheia algoritmul\n",
        "  if not w_changed:\n",
        "    print(\"Nu a fost detectata nicio schimbare a ponderilor la epoca #{}. Algoritmul se poate incheia\".format(epoch))\n",
        "    break"
      ],
      "metadata": {
        "id": "rmJOIu2QAeil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient descent\n",
        "Să se implementeze algoritmul \"gradient descent\" pentru funcții de cost întâlnite în mod obișnuit."
      ],
      "metadata": {
        "id": "5wH9x35AKdkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "63vyVnDtMQ0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definim functia de cost\n",
        "# TODO: incercati sa implementati si alte functii de cost, e.g. modul.\n",
        "def J(x):\n",
        "\treturn x**2.0\n",
        "\n",
        "# Definim derivata functiei de cost - ideal ar fi sa fie calculata automat\n",
        "def dJ(x):\n",
        "\treturn x * 2.0"
      ],
      "metadata": {
        "id": "YFAFBeEmNaHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definim suportul functiei de cost\n",
        "suport_fct = np.asarray([[-3.0, 3.0]])\n",
        "# Alegem un numar de iteratii in care sa calculam functia de cost\n",
        "n_iter = 50\n",
        "# Alegem rata de invatare\n",
        "# TODO incercati diferite valori pentru rata de invatare si urmariti comportamentul gradientului\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Esantionam valori din intervalul suportului functiei cu pas de 0.1\n",
        "f_input = np.arange(suport_fct[0,0], suport_fct[0,1]+0.1, 0.1)\n",
        "# Calculam valorile functiei in punctele esantionate\n",
        "f_output = J(f_input)\n",
        "# Afisam forma functiei de cost\n",
        "plt.plot(f_input, f_output)\n",
        "plt.xlabel(\"w\")\n",
        "plt.ylabel(\"J(w)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "floWehpmUuxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retinem toate valoriile w si J(w)\n",
        "lista_w, lista_J_w = [], []\n",
        "# Alegem un punct aleator de unde incepem algoritmul\n",
        "w = np.random.uniform(suport_fct[0, 0], suport_fct[0, 1])\n",
        "print (\"Pornim algoritmul de la valoarea {}.\".format(w))\n",
        "\n",
        "# Retinem valorile initiale ale w si J(w)\n",
        "lista_w.append(w)\n",
        "lista_J_w.append(J(w))\n",
        "\n",
        "for i in range(n_iter):\n",
        "\t# Calculam gradientul\n",
        "\t# TODO\n",
        "\t# Actualizam w\n",
        "\t# TODO\n",
        "\t# Calculam valoarea in noul punct w\n",
        "\t# TODO\n",
        "\t# Retinem noile valori ale w si J(w) \n",
        "\t# TODO\n",
        "\t# Afisam pe ecran noile valori w si J(w)\n",
        "\t# TODO\n",
        "\n",
        "\n",
        "# Afisam functia de cost initiala\n",
        "plt.plot(f_input, f_output)\n",
        "# Adaugam pe grafic valorile w si J(w) gasite\n",
        "plt.plot(lista_w, lista_J_w, '.-', color='red')\n",
        "plt.xlabel(\"w\")\n",
        "plt.ylabel(\"J(w)\")\n",
        "# Afisam graficul final\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v8wHTBrdKvC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation\n",
        "Să se implementeze algoritmul de propagare înapoi pentru o problemă de clasificare a datelor în 3 clase.\n",
        "Exemplu adaptat de [aici](https://www.askpython.com/python/examples/backpropagation-in-python)."
      ],
      "metadata": {
        "id": "ew31qoz2SiNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3r7MKm0XTp5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incarcam baza de date \"Iris\": https://archive.ics.uci.edu/ml/datasets/iris\n",
        "data = load_iris()\n",
        "# Extragem datele si etichetele din baza de date\n",
        "X=data.data\n",
        "y=data.target\n",
        "# Impartim baza de date in train (80%) vs test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=4)"
      ],
      "metadata": {
        "id": "Iv-L3S6bTtRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "iterations = 5000\n",
        "N = y_train.size\n",
        " \n",
        "# Dimensiunea intrarii\n",
        "input_size = 4\n",
        " \n",
        "# Dimensiunea stratului ascuns\n",
        "hidden_size = 3\n",
        " \n",
        "# Dimensiunea iesirii\n",
        "output_size = 3 \n",
        " \n",
        "# Variabila in care vom stoca metricile\n",
        "results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])"
      ],
      "metadata": {
        "id": "gTHOWhTYT0Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializam seed-ul generatorului aleator\n",
        "np.random.seed(10)\n",
        " \n",
        "# Initializam ponderile dintre stratul de intrare si stratul ascuns\n",
        "W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))   \n",
        " \n",
        "# Initializam ponderile dintre stratul ascuns si stratul de iesire\n",
        "W2 = np.random.normal(scale=0.5, size=(hidden_size , output_size)) "
      ],
      "metadata": {
        "id": "YUbIuB1UTwVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definim functia sigmoid\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Definim functia MSE\n",
        "def mean_squared_error(y_pred, y_true):\n",
        "  return ((y_pred - y_true)**2).sum() / (y_pred.size * 2)\n",
        "\n",
        "# Definim acuratetea\n",
        "def accuracy(y_pred, y_true):\n",
        "  acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
        "  return acc.mean()\n",
        "\n",
        "# Definim functia one_hot\n",
        "def one_hot(x):\n",
        "  result = np.zeros((x.size, x.max()+1))\n",
        "  result[np.arange(x.size), x] = 1\n",
        "  return result"
      ],
      "metadata": {
        "id": "iRrrdqXpUA-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformam etichetele in vectori one-hot\n",
        "one_hot_y_train = one_hot(y_train)\n",
        "one_hot_y_test = one_hot(y_test)\n",
        "\n",
        "for itr in range(iterations):    \n",
        "  # Propagare inainte prin primul strat ascuns\n",
        "  A1 = sigmoid(np.dot(X_train, W1))\n",
        "\n",
        "  # Propagare inainte prin stratul de iesire\n",
        "  A2 = sigmoid(np.dot(A1, W2))\n",
        "\n",
        "  # Calculul erorii si al acuratetii\n",
        "  mse = mean_squared_error(A2, one_hot_y_train)\n",
        "  acc = accuracy(A2, one_hot_y_train)\n",
        "\n",
        "  # Retinem mse si acc de la fiecare pas\n",
        "  results=results.append({\"mse\":mse, \"accuracy\":acc},ignore_index=True )\n",
        "    \n",
        "  # Backpropagation\n",
        "  # Calculam derivata pentru ponderile dintre ultimul strat si stratul ascuns\n",
        "  E1 = A2 - one_hot_y_train\n",
        "  dW1 = E1 * A2 * (1 - A2)\n",
        "\n",
        "  # Calculam derivata pentru ponderile dintre stratul ascuns si stratul de intrare\n",
        "  E2 = np.dot(dW1, W2.T)\n",
        "  dW2 = E2 * A1 * (1 - A1)\n",
        "\n",
        "  # Calculam gradientul - impartirea la N apare in urma derivarii functiei de cost\n",
        "  W2_update = np.dot(A1.T, dW1) / N\n",
        "  W1_update = np.dot(X_train.T, dW2) / N\n",
        "\n",
        "  # Actualizam ponderile\n",
        "  # TODO\n",
        "\n",
        "# Afisam pe grafic MSE si accuracy\n",
        "results.mse.plot(title=\"Mean Squared Error\")\n",
        "results.accuracy.plot(title=\"Accuracy\")\n",
        "\n",
        "# Rulam modelul antrenat pe baza de date de test\n",
        "# TODO: rulati secventa de test prin rețeaua antrenată. Ieșirea rețelei va fi stocată în variabila A2 pentru a putea fi utilizată mai jos\n",
        " \n",
        "acc = accuracy(A2, one_hot_y_test)\n",
        "print(\"Accuracy: {}\".format(acc))"
      ],
      "metadata": {
        "id": "GRfddHzcSoiy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}